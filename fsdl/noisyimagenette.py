# AUTOGENERATED! DO NOT EDIT! File to edit: 01_noisyimagenette.ipynb (unless otherwise specified).

__all__ = ['source', 'df', 'get_inverse_transform', 'lbl_dict', 'lbl_dict_inv', 'get_dls', 'dls_5', 'learn_5',
           'train_preds', 'val_preds', 'train_ordered_label_errors', 'noisy_train', 'train_preds',
           'train_ordered_label_errors', 'preds_50', 'confidence', 'noisy_train_50', 'high_confident_noisy']

# Cell
from fastai.vision.all import *
from pathlib import Path

import pandas as pd

# Cell
source = untar_data(URLs.IMAGENETTE)
df: pd.DataFrame = pd.read_csv(source/'noisy_imagenette.csv')

# Cell
lbl_dict = dict(
    n01440764='tench',
    n02102040='English springer',
    n02979186='cassette player',
    n03000684='chain saw',
    n03028079='church',
    n03394916='French horn',
    n03417042='garbage truck',
    n03425413='gas pump',
    n03445777='golf ball',
    n03888257='parachute'
)
lbl_dict_inv = {v: k for k, v in lbl_dict.items()}
def get_inverse_transform(vocab):
  return L(vocab).map(lbl_dict_inv)

# Cell
set_seed(42, reproducible=True)

# Cell
def get_dls(file, noice_pct=5, size=128, soft_targets=False):

  if soft_targets:
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                    get_x=ColReader('path', pref=source),
                    get_y=Pipeline([ColReader(f'soft_targets'), lbl_dict.__getitem__]),
                    splitter=ColSplitter(), #uses the bool value in is_valid column on the dataframe to identify the validation set (without any noise).
                    item_tfms=[RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)],
                    batch_tfms=Normalize.from_stats(*imagenet_stats))

  else:
    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),
                    get_x=ColReader('path', pref=source),
                    get_y=Pipeline([ColReader(f'noisy_labels_{noice_pct}'), lbl_dict.__getitem__]),
                    splitter=ColSplitter(), #uses the bool value in is_valid column on the dataframe to identify the validation set (without any noise).
                    item_tfms=[RandomResizedCrop(size, min_scale=0.35), FlipItem(0.5)],
                    batch_tfms=Normalize.from_stats(*imagenet_stats))
  dls = dblock.dataloaders(file)
  return dls

# Cell
dls_5 = get_dls(df, 5, size=224)

# Cell
learn_5 = cnn_learner(dls_5, resnet18, metrics=[accuracy, RocAuc()])

# Cell
learn_5.fine_tune(epochs=5, base_lr=1e-3, freeze_epochs=3)

# Cell
learn_5.save('learn_5')

# Cell
train_preds = learn_5.get_preds(ds_idx=0, with_decoded=True)

# Cell
val_preds = learn_5.get_preds(ds_idx=1, with_decoded=True)

# Cell
from cleanlab.pruning import get_noise_indices

# Cell
train_ordered_label_errors = get_noise_indices(s=train_preds[1].numpy(), #targets
                             psx=train_preds[0].numpy(),#predictions_prob
                             sorted_index_method='normalized_margin')

# Internal Cell
print("We found {} label errors.".format(len(train_ordered_label_errors)))

# Cell
noisy_train = train_df.loc[train_ordered_label_errors]

# Cell
train_preds = learn_50.get_preds(ds_idx=0, with_decoded=True)
from cleanlab.pruning import get_noise_indices
# Cell
# Get the noisy indices
train_ordered_label_errors = get_noise_indices(s=train_preds[1].numpy(), #targets
                             psx=train_preds[0].numpy(),#predictions_prob
                             sorted_index_method='normalized_margin')

# Cell
#Get the predictions for the training dataset
preds_50 = np.array(get_inverse_transform(L(list(train_preds[2])).map(dls_50.vocab)));
train_df['predictions'] = preds_50
# Add confidence & confidenceRange
confidence = torch.max(train_preds[0], axis=-1).values
train_df['confidence'] = confidence
train_df['confidenceRange'] = pd.cut(train_df.confidence, bins=[0.0, 0.6, 0.8, 1.0], labels=['<60', '60-80', '80+'])

noisy_train_50 = train_df.loc[train_ordered_label_errors]
df['soft_targets'] = df['noisy_labels_50']
high_confident_noisy = train_df.loc[train_ordered_label_errors][train_df.confidenceRange == '80+'].index

for i, row in df.iterrows():
  if not row['is_valid'] and i in high_confident_noisy:
    pseudo = preds_50[i]
    df.at[i, 'soft_targets'] = pseudo